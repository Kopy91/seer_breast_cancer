{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preface\n",
    "...\n",
    "# # reading in data as df\n",
    "# df = pd.read_csv('Breast_Cancer.csv', delimiter=',')\n",
    "\n",
    "# # correcting typos\n",
    "# df = df.rename(columns={'T Stage ':'T Stage'})\n",
    "# df = df.rename(columns={'Reginol Node Positive': 'Regional Node Positive'})\n",
    "\n",
    "# # remapping target column\n",
    "# df.loc[:,'Status_encoded'] = df.loc[:,'Status'].map({'Alive':0, 'Dead':1})\n",
    "\n",
    "# # new features \n",
    "# # ['Node_Examined_Pos_Rate']: Positive Nodes per Examined Nodes\n",
    "# df.loc[:,'Node_Exam_Pos_Rate'] = df.loc[:,'Regional Node Positive']/df.loc[:,'Regional Node Examined']\n",
    "# #['Progesteron_Estrogen_Status']: Positive status if status of both receptors is positive\n",
    "# mask = (df['Estrogen Status'] == 'Positive') | (df['Progesterone Status'] == 'Positive')\n",
    "# conditions = [mask, ~mask]\n",
    "# values = ['Positive', 'Negative']\n",
    "# df['Estrogen_Progesteron_Status'] = np.select(conditions, values)\n",
    "\n",
    "\n",
    "# # changing dtypes of columns as needed\n",
    "# dtypes_columns = {'Age' : 'int64',\n",
    "# 'Race' : 'category',\n",
    "# 'Marital Status' : 'category',\n",
    "# 'T Stage' : 'category', \n",
    "# 'N Stage' : 'category',\n",
    "# '6th Stage' : 'category',\n",
    "# 'differentiate' : 'category',\n",
    "# 'Grade' : 'category',\n",
    "# 'A Stage' : 'category', \n",
    "# 'Tumor Size' : 'int64',\n",
    "# 'Estrogen Status' : 'category',\n",
    "# 'Progesterone Status' : 'category',\n",
    "# 'Regional Node Examined' : 'int64',\n",
    "# 'Regional Node Positive' : 'int64',\n",
    "# 'Survival Months' : 'int64',\n",
    "# 'Status' : 'category',\n",
    "# 'Status_encoded' : 'int64',\n",
    "# 'Node_Exam_Pos_Rate': 'float64',\n",
    "# 'Estrogen_Progesteron_Status': 'category'}\n",
    "# df = df.astype(dtypes_columns)\n",
    "\n",
    "# # drop 'Grade' columns because the information is the same as in the 'differentiate' column \n",
    "# df.drop('Grade', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# # # creating target and features \n",
    "# # target = df.loc[:,'Status_encoded']\n",
    "# # features = df.drop('Status', axis=1)\n",
    "# # features = features.drop('Status_encoded', axis=1)\n",
    "\n",
    "# # # train and test split\n",
    "# # features_train, features_test, target_train, target_test = train_test_split(features, \n",
    "# #                                                                             target, \n",
    "# #                                                                             random_state=42,\n",
    "# #                                                                             test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kopyt\\AppData\\Local\\Temp\\ipykernel_7456\\1183943992.py:19: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn')\n"
     ]
    }
   ],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier # pipeline builder can handle\n",
    "\n",
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in data as df\n",
    "df = pd.read_csv('Breast_Cancer.csv', delimiter=',')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    \"\"\"Returns cleaned DataFrame.\n",
    "    \n",
    "    Correcting typos\n",
    "    Transform datatypes from object to category\n",
    "    Drop column 'Grade'\n",
    "\n",
    "    Args: \n",
    "        df (pd.DataFrame) : uncleaned DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        df  (pd.DataFrame) : cleaned DataFrame\n",
    "    \"\"\"\n",
    "    # correcting typos\n",
    "    df = df.rename(columns={'T Stage ':'T Stage'})\n",
    "    df = df.rename(columns={'Reginol Node Positive': 'Regional Node Positive'})\n",
    "\n",
    "    # remapping target column\n",
    "    df.loc[:,'Status_encoded'] = df.loc[:,'Status'].map({'Alive':0, 'Dead':1})\n",
    "\n",
    "    # changing dtypes of columns as needed\n",
    "    dtypes_columns = {'Age' : 'int64',\n",
    "        'Race' : 'category',\n",
    "        'Marital Status' : 'category',\n",
    "        'T Stage' : 'category', \n",
    "        'N Stage' : 'category',\n",
    "        '6th Stage' : 'category',\n",
    "        'differentiate' : 'category',\n",
    "        'Grade' : 'category',\n",
    "        'A Stage' : 'category', \n",
    "        'Tumor Size' : 'int64',\n",
    "        'Estrogen Status' : 'category',\n",
    "        'Progesterone Status' : 'category',\n",
    "        'Regional Node Examined' : 'int64',\n",
    "        'Regional Node Positive' : 'int64',\n",
    "        'Survival Months' : 'int64',\n",
    "        'Status' : 'category',\n",
    "        'Status_encoded' : 'int64',\n",
    "        'Node_Exam_Pos_Rate': 'float64',\n",
    "        'Estrogen_Progesteron_Status': 'category'}\n",
    "    df = df.astype(dtypes_columns)\n",
    "\n",
    "    # drop 'Grade' columns because the information is the same as in the 'differentiate' column\n",
    "    df.drop('Status', axis=1, inplace=True)\n",
    "    df.drop('Grade', axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save clean_data function as pickle\n",
    "pickle.dump(clean_data, open('clean_data.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load clean_data\n",
    "file_name = 'clean_data.p'\n",
    "clean_data = pickle.load(open(file_name, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    \"\"\"Add new Features to Dataframe.\n",
    "    \n",
    "    Add features Node_Exam_Pos_Rate and Estrogen Status\n",
    "       \n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe\n",
    "        ohe_transformer: The fitted ohe_transformer\n",
    "    \n",
    "    Returns:\n",
    "        (pd.DataFrame) : Dataframe with new Features\n",
    "    \"\"\" \n",
    "\n",
    "    # ['Node_Examined_Pos_Rate']: Positive Nodes per Examined Nodes\n",
    "    df.loc[:,'Node_Exam_Pos_Rate'] = df.loc[:,'Reginol Node Positive']/df.loc[:,'Regional Node Examined']\n",
    "\n",
    "    #['Progesteron_Estrogen_Status']: Positive status if status of both receptors is positive\n",
    "    mask = (df['Estrogen Status'] == 'Positive') | (df['Progesterone Status'] == 'Positive')\n",
    "    conditions = [mask, ~mask]\n",
    "    values = ['Positive', 'Negative']\n",
    "    df['Estrogen_Progesteron_Status'] = np.select(conditions, values)\n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save feature_engineering function as pickle\n",
    "pickle.dump(feature_engineering, open('feature_engineering.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load feature_engineering\n",
    "file_name = 'feature_engineering.p'\n",
    "feature_engineering = pickle.load(open(file_name, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Race</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>T Stage</th>\n",
       "      <th>N Stage</th>\n",
       "      <th>6th Stage</th>\n",
       "      <th>differentiate</th>\n",
       "      <th>A Stage</th>\n",
       "      <th>Tumor Size</th>\n",
       "      <th>Estrogen Status</th>\n",
       "      <th>Progesterone Status</th>\n",
       "      <th>Regional Node Examined</th>\n",
       "      <th>Regional Node Positive</th>\n",
       "      <th>Survival Months</th>\n",
       "      <th>Node_Exam_Pos_Rate</th>\n",
       "      <th>Estrogen_Progesteron_Status</th>\n",
       "      <th>Status_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68</td>\n",
       "      <td>White</td>\n",
       "      <td>Married</td>\n",
       "      <td>T1</td>\n",
       "      <td>N1</td>\n",
       "      <td>IIA</td>\n",
       "      <td>Poorly differentiated</td>\n",
       "      <td>Regional</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>White</td>\n",
       "      <td>Married</td>\n",
       "      <td>T2</td>\n",
       "      <td>N2</td>\n",
       "      <td>IIIA</td>\n",
       "      <td>Moderately differentiated</td>\n",
       "      <td>Regional</td>\n",
       "      <td>35</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>62</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58</td>\n",
       "      <td>White</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>T3</td>\n",
       "      <td>N3</td>\n",
       "      <td>IIIC</td>\n",
       "      <td>Moderately differentiated</td>\n",
       "      <td>Regional</td>\n",
       "      <td>63</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>75</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>White</td>\n",
       "      <td>Married</td>\n",
       "      <td>T1</td>\n",
       "      <td>N1</td>\n",
       "      <td>IIA</td>\n",
       "      <td>Poorly differentiated</td>\n",
       "      <td>Regional</td>\n",
       "      <td>18</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>White</td>\n",
       "      <td>Married</td>\n",
       "      <td>T2</td>\n",
       "      <td>N1</td>\n",
       "      <td>IIB</td>\n",
       "      <td>Poorly differentiated</td>\n",
       "      <td>Regional</td>\n",
       "      <td>41</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age   Race Marital Status T Stage N Stage 6th Stage  \\\n",
       "0   68  White        Married      T1      N1       IIA   \n",
       "1   50  White        Married      T2      N2      IIIA   \n",
       "2   58  White       Divorced      T3      N3      IIIC   \n",
       "3   58  White        Married      T1      N1       IIA   \n",
       "4   47  White        Married      T2      N1       IIB   \n",
       "\n",
       "               differentiate   A Stage  Tumor Size Estrogen Status  \\\n",
       "0      Poorly differentiated  Regional           4        Positive   \n",
       "1  Moderately differentiated  Regional          35        Positive   \n",
       "2  Moderately differentiated  Regional          63        Positive   \n",
       "3      Poorly differentiated  Regional          18        Positive   \n",
       "4      Poorly differentiated  Regional          41        Positive   \n",
       "\n",
       "  Progesterone Status  Regional Node Examined  Regional Node Positive  \\\n",
       "0            Positive                      24                       1   \n",
       "1            Positive                      14                       5   \n",
       "2            Positive                      14                       7   \n",
       "3            Positive                       2                       1   \n",
       "4            Positive                       3                       1   \n",
       "\n",
       "   Survival Months  Node_Exam_Pos_Rate Estrogen_Progesteron_Status  \\\n",
       "0               60            0.041667                    Positive   \n",
       "1               62            0.357143                    Positive   \n",
       "2               75            0.500000                    Positive   \n",
       "3               84            0.500000                    Positive   \n",
       "4               50            0.333333                    Positive   \n",
       "\n",
       "   Status_encoded  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding two new features\n",
    "df = feature_engineering(df)\n",
    "\n",
    "# clean dataframe\n",
    "df_clean = clean_data(df)\n",
    "df_clean.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating target and features \n",
    "target = df_clean.loc[:,'Status_encoded']\n",
    "#features = df.drop('Status', axis=1)\n",
    "features = df_clean.drop('Status_encoded', axis=1)\n",
    "\n",
    "# train and test split\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, \n",
    "                                                                            target, \n",
    "                                                                            random_state=42,\n",
    "                                                                            test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save features_test and target_test as 'features_test.csv' and 'target_test.csv' respectively\n",
    "features_test.to_csv('features_test.csv', index=False)\n",
    "target_test.to_csv('target_test.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating lists of categorical, ordinal and numerical columns\n",
    "cat_cols = ['Race', 'Marital Status', 'Estrogen Status', 'Progesterone Status', 'Estrogen_Progesteron_Status']\n",
    "ord_cols = ['T Stage', 'N Stage', '6th Stage', 'differentiate', 'A Stage']\n",
    "num_cols = [col for col in features_train.select_dtypes(include=[\"int64\",\"float64\"])]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our baseline model will be a DecisionTreeClassifier for easy interpretability.\n",
    "\n",
    "First we have to deal with the inbalance of our target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>DecisionTreeClassifier with OVERSAMPLING</td>\n",
       "      <td>DecisionTreeClassifier with UNDERSAMPLING</td>\n",
       "      <td>DecisionTreeClassifier with CLASS_WEIGHTS</td>\n",
       "      <td>DecisionTreeClassifier with SMOTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>89.081886</td>\n",
       "      <td>77.419355</td>\n",
       "      <td>92.059553</td>\n",
       "      <td>88.585608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>69.69697</td>\n",
       "      <td>42.657343</td>\n",
       "      <td>85.185185</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>65.714286</td>\n",
       "      <td>87.142857</td>\n",
       "      <td>65.714286</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>67.647059</td>\n",
       "      <td>57.276995</td>\n",
       "      <td>74.193548</td>\n",
       "      <td>64.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best model</th>\n",
       "      <td>DecisionTreeClassifier(max_depth=4, random_sta...</td>\n",
       "      <td>DecisionTreeClassifier(max_depth=2, random_sta...</td>\n",
       "      <td>DecisionTreeClassifier(max_depth=2, random_sta...</td>\n",
       "      <td>DecisionTreeClassifier(max_depth=6, random_sta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            0  \\\n",
       "name                 DecisionTreeClassifier with OVERSAMPLING   \n",
       "accuracy                                            89.081886   \n",
       "precision                                            69.69697   \n",
       "recall                                              65.714286   \n",
       "f1                                                  67.647059   \n",
       "best model  DecisionTreeClassifier(max_depth=4, random_sta...   \n",
       "\n",
       "                                                            1  \\\n",
       "name                DecisionTreeClassifier with UNDERSAMPLING   \n",
       "accuracy                                            77.419355   \n",
       "precision                                           42.657343   \n",
       "recall                                              87.142857   \n",
       "f1                                                  57.276995   \n",
       "best model  DecisionTreeClassifier(max_depth=2, random_sta...   \n",
       "\n",
       "                                                            2  \\\n",
       "name                DecisionTreeClassifier with CLASS_WEIGHTS   \n",
       "accuracy                                            92.059553   \n",
       "precision                                           85.185185   \n",
       "recall                                              65.714286   \n",
       "f1                                                  74.193548   \n",
       "best model  DecisionTreeClassifier(max_depth=2, random_sta...   \n",
       "\n",
       "                                                            3  \n",
       "name                        DecisionTreeClassifier with SMOTE  \n",
       "accuracy                                            88.585608  \n",
       "precision                                                70.0  \n",
       "recall                                                   60.0  \n",
       "f1                                                  64.615385  \n",
       "best model  DecisionTreeClassifier(max_depth=6, random_sta...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing different resampling methods\n",
    "# running time: 9.3s\n",
    "\n",
    "search_space = {'estimator__max_depth': range(2, 16, 2),\n",
    "                'estimator__class_weight': [None, 'balanced']}\n",
    "samplers = [('oversampling', RandomOverSampler(random_state=42)),\n",
    "            ('undersampling', RandomUnderSampler(random_state=42)),\n",
    "            ('class_weights', 'passthrough'),\n",
    "            ('smote', SMOTE(random_state=42))\n",
    "           ]\n",
    "sampling_results = []\n",
    "\n",
    "# go through every sampler\n",
    "for name, sampler in samplers:\n",
    "    # sampling\n",
    "    imb_pipe = Pipeline([('preprocessing', ColumnTransformer(transformers=[\n",
    "                            ('encoder', OneHotEncoder(handle_unknown='ignore'), cat_cols),\n",
    "                            ('ord_transformer', OrdinalEncoder(), ord_cols)\n",
    "                        ], remainder='passthrough')),\n",
    "                        ('sampler', sampler),\n",
    "                        ('estimator', DecisionTreeClassifier(random_state=42))\n",
    "                        ])\n",
    "    \n",
    "    # gridsearch and CV\n",
    "    grid_tree = GridSearchCV(estimator=imb_pipe, \n",
    "                        param_grid=search_space,\n",
    "                        n_jobs=-1,\n",
    "                        cv=5,\n",
    "                        scoring='f1')\n",
    "    \n",
    "    grid_tree.fit(features_train, target_train)\n",
    "\n",
    "    target_pred_tree = grid_tree.predict(features_test)\n",
    "\n",
    "    score = {'name': \"DecisionTreeClassifier with \" + name.upper(),\n",
    "        'accuracy': accuracy_score(target_test, target_pred_tree) * 100,\n",
    "        'precision': precision_score(target_test, target_pred_tree) * 100,\n",
    "        'recall': recall_score(target_test, target_pred_tree) * 100,\n",
    "        'f1': f1_score(target_test, target_pred_tree) * 100,\n",
    "        'best model': grid_tree.best_estimator_.named_steps['estimator']\n",
    "        }\n",
    "    sampling_results.append(score)\n",
    "# show results \n",
    "pd.DataFrame(sampling_results).T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that class_weights performs best for sampling. We will use the parameter class_weight for resampling our models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Confusion Matrix für Baseline Modell und Baselien Modell in model_results Liste aufneheen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of metrics of all models\n",
    "model_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score\n",
      "0.6088559433566457\n",
      "best model parameter\n",
      "{'estimator__class_weight': None, 'estimator__max_depth': 2}\n",
      "Baseline model DecisionTreeClassifier(max_depth=2, random_state=42)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>Baseline model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>92.059553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>85.185185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>65.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>74.193548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0\n",
       "name       Baseline model\n",
       "accuracy        92.059553\n",
       "precision       85.185185\n",
       "recall          65.714286\n",
       "f1              74.193548"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# our baseline model\n",
    "\n",
    "pipeline_baseline = Pipeline([('preprocessing', ColumnTransformer(transformers=[\n",
    "                            ('encoder', OneHotEncoder(handle_unknown='ignore'), cat_cols),\n",
    "                            ('ord_transformer', OrdinalEncoder(), ord_cols)\n",
    "                        ], remainder='passthrough')),\n",
    "                        ('estimator', DecisionTreeClassifier(class_weight='balanced', random_state=42))])\n",
    "\n",
    "grid_tree = GridSearchCV(estimator=pipeline_baseline, \n",
    "                        param_grid=search_space,\n",
    "                        n_jobs=-1,\n",
    "                        cv=5,\n",
    "                        scoring='f1')\n",
    "grid_tree.fit(features_train, target_train)\n",
    "\n",
    "# Print the training score of the best model\n",
    "print(\"best score\")\n",
    "print(grid_tree.best_score_)\n",
    "\n",
    "# Print the model parameters of the best model\n",
    "print(\"best model parameter\")\n",
    "print(grid_tree.best_params_)\n",
    "\n",
    "baseline_model = grid_tree.best_estimator_['estimator']\n",
    "print(\"Baseline model\", baseline_model)\n",
    "\n",
    "# Print the val score of the best model\n",
    "#predict\n",
    "target_pred_tree = grid_tree.best_estimator_.predict(features_test)\n",
    "\n",
    "#save\n",
    "scores = {'name': \"Baseline model\",\n",
    "          'accuracy': accuracy_score(target_test, target_pred_tree) * 100,\n",
    "          'precision': precision_score(target_test, target_pred_tree) * 100,\n",
    "          'recall': recall_score(target_test, target_pred_tree) * 100,\n",
    "          'f1': f1_score(target_test, target_pred_tree) * 100,\n",
    "        }\n",
    "model_results.append(scores)\n",
    "    \n",
    "#show results\n",
    "pd.DataFrame(model_results).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# confusion matrix for predictions on test data\n",
    "plt.style.use('classic')\n",
    "test_pred = grid_tree.best_estimator_.predict(features_test)\n",
    "confusion_matrix(target_test, test_pred)\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(grid_tree, features_test, target_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95       333\n",
      "           1       0.85      0.66      0.74        70\n",
      "\n",
      "    accuracy                           0.92       403\n",
      "   macro avg       0.89      0.82      0.85       403\n",
      "weighted avg       0.92      0.92      0.92       403\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# report\n",
    "report = classification_report(target_test, target_pred_tree)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot our decision tree. TODO: Was zur Gini-Impurity sagen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This ColumnTransformer instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m plot_tree(decision_tree\u001b[39m=\u001b[39mbaseline_model,\n\u001b[1;32m----> 2\u001b[0m           feature_names\u001b[39m=\u001b[39mgrid_tree\u001b[39m.\u001b[39;49mestimator\u001b[39m.\u001b[39;49mnamed_steps[\u001b[39m'\u001b[39;49m\u001b[39mpreprocessing\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mget_feature_names_out(),\n\u001b[0;32m      3\u001b[0m           class_names\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mAlive\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mDead\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m      4\u001b[0m           filled\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\kopyt\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:505\u001b[0m, in \u001b[0;36mColumnTransformer.get_feature_names_out\u001b[1;34m(self, input_features)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_feature_names_out\u001b[39m(\u001b[39mself\u001b[39m, input_features\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    486\u001b[0m     \u001b[39m\"\"\"Get output feature names for transformation.\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \n\u001b[0;32m    488\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[39m        Transformed feature names.\u001b[39;00m\n\u001b[0;32m    504\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 505\u001b[0m     check_is_fitted(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    506\u001b[0m     input_features \u001b[39m=\u001b[39m _check_feature_names_in(\u001b[39mself\u001b[39m, input_features)\n\u001b[0;32m    508\u001b[0m     \u001b[39m# List of tuples (name, feature_names_out)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kopyt\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1390\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1385\u001b[0m     fitted \u001b[39m=\u001b[39m [\n\u001b[0;32m   1386\u001b[0m         v \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m \u001b[39mvars\u001b[39m(estimator) \u001b[39mif\u001b[39;00m v\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m v\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1387\u001b[0m     ]\n\u001b[0;32m   1389\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fitted:\n\u001b[1;32m-> 1390\u001b[0m     \u001b[39mraise\u001b[39;00m NotFittedError(msg \u001b[39m%\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mtype\u001b[39m(estimator)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This ColumnTransformer instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "plot_tree(decision_tree=baseline_model,\n",
    "          feature_names=grid_tree.estimator.named_steps['preprocessing'].get_feature_names_out(),\n",
    "          class_names=['Alive','Dead'],\n",
    "          filled=True);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider the roc-auc curve of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print roc-curve\n",
    "\n",
    "# create DataFrame with one column named prediction\n",
    "df_pred_test = pd.DataFrame(target_pred_tree, columns=['prediction'])\n",
    "\n",
    "# predict probabilities and add them as new column\n",
    "df_pred_test.loc[:, 'probability'] = grid_tree.best_estimator_.predict_proba(features_test)[:, 1]  \n",
    "\n",
    "# calculate roc-curve\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "false_positive_rate, recall, threshold = roc_curve(target_test, df_pred_test.loc[:, 'probability']) \n",
    "\n",
    "# plotting\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# figure and axes intialisation\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# reference lines\n",
    "ax.plot([0, 1], ls = \"--\")  # blue diagonal\n",
    "ax.plot([0, 0], [1, 0], c=\".7\", ls='--')  # grey vertical\n",
    "ax.plot([1, 1], c=\".7\", ls='--')  # grey horizontal\n",
    "\n",
    "# roc curve\n",
    "ax.plot(false_positive_rate, recall)\n",
    "\n",
    "# labels\n",
    "ax.set_title(\"Receiver Operating Characteristic\")\n",
    "ax.set_xlabel(\"False Positive Rate\")\n",
    "ax.set_ylabel(\"Recall\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 25\u001b[0m\n\u001b[0;32m     18\u001b[0m model_rfc \u001b[39m=\u001b[39m GridSearchCV(estimator\u001b[39m=\u001b[39mbaseline_model,\n\u001b[0;32m     19\u001b[0m                         param_grid\u001b[39m=\u001b[39msearch_space_rfc,\n\u001b[0;32m     20\u001b[0m                         scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mf1\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     21\u001b[0m                         cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m,\n\u001b[0;32m     22\u001b[0m                         n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[39m# fitting model\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m model_rfc\u001b[39m.\u001b[39;49mfit(features_train[selected_features], target_train)\n\u001b[0;32m     27\u001b[0m \u001b[39m# Print the training score of the best model\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mbest score \u001b[39m\u001b[39m\"\u001b[39m, model_rfc\u001b[39m.\u001b[39mbest_score_)\n",
      "File \u001b[1;32mc:\\Users\\kopyt\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\kopyt\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\kopyt\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\kopyt\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\kopyt\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1061\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1060\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1061\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1062\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\kopyt\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:938\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    936\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    937\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 938\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    939\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    940\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\kopyt\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 542\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    543\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    544\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kopyt\\anaconda3\\lib\\concurrent\\futures\\_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m    451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m--> 453\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\kopyt\\anaconda3\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier with GridSearch\n",
    "# running time: 4:12min to run\n",
    "\n",
    "selected_features = cat_cols + ord_cols + num_cols\n",
    "\n",
    "\n",
    "# creating baseline model pipeline\n",
    "baseline_model = Pipeline([('preprocessing', ColumnTransformer(transformers=[\n",
    "                              ('cat_transformer', OneHotEncoder(drop='if_binary'), cat_cols), \n",
    "                              ('ord_transformer', OrdinalEncoder(), ord_cols)\n",
    "                         ], remainder='passthrough')),\n",
    "                         ('model', RandomForestClassifier(class_weight='balanced', random_state=42, n_jobs=-1))])\n",
    "\n",
    "search_space_rfc = {'model__max_depth': np.geomspace(start=1, stop=250, num=10, dtype='int'),\n",
    "                   'model__min_samples_leaf': np.geomspace(start=1, stop=40, num=10, dtype='int'),\n",
    "                    'model__n_estimators': np.geomspace(start=25, stop=300, num=10, dtype='int')}\n",
    "\n",
    "model_rfc = GridSearchCV(estimator=baseline_model,\n",
    "                        param_grid=search_space_rfc,\n",
    "                        scoring='f1',\n",
    "                        cv=5,\n",
    "                        n_jobs=-1)\n",
    "\n",
    "# fitting model\n",
    "model_rfc.fit(features_train[selected_features], target_train)\n",
    "\n",
    "# Print the training score of the best model\n",
    "print(\"best score \", model_rfc.best_score_)\n",
    "\n",
    "# Print the model parameters of the best model\n",
    "print(\"best model parameter \", model_rfc.best_params_)\n",
    "\n",
    "target_test_pred_rfc = model_rfc.best_estimator_.predict(features_test)\n",
    "\n",
    "scores = {'name': \"RandomForestClassifier with all features selected\",\n",
    "          'accuracy': accuracy_score(target_test,target_test_pred_rfc) * 100,\n",
    "          'precision': precision_score(target_test,target_test_pred_rfc) * 100,\n",
    "          'recall': recall_score(target_test,target_test_pred_rfc) * 100,\n",
    "          'f1': f1_score(target_test,target_test_pred_rfc) * 100,\n",
    "         }\n",
    "model_results.append(scores)\n",
    "pd.DataFrame(model_results).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best model_rfc as pickle\n",
    "pickle.dump(model_rfc, open('model_rfc.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model_rfc\n",
    "file_name = 'model_rfc.p'\n",
    "#with (open(file_name, \"rb\")) as f:\n",
    "model_rfc = pickle.load(open(file_name, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# confusion matrix for predictions on test data\n",
    "plt.style.use('classic')\n",
    "test_pred = model_rfc.best_estimator_.predict(features_test[selected_features])\n",
    "confusion_matrix(target_test, test_pred)\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(model_rfc, features_test[selected_features], target_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report\n",
    "report = classification_report(target_test, target_test_pred_rfc)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print roc-curve\n",
    "\n",
    "# create DataFrame with one column named prediction\n",
    "df_pred_test = pd.DataFrame(target_test_pred_rfc, columns=['prediction'])\n",
    "\n",
    "# predict probabilities and add them as new column\n",
    "df_pred_test.loc[:, 'probability'] = model_rfc.best_estimator_.predict_proba(features_test)[:, 1]  \n",
    "\n",
    "# calculate roc-curve\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "false_positive_rate, recall, threshold = roc_curve(target_test, df_pred_test.loc[:, 'probability']) \n",
    "\n",
    "# plotting\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# figure and axes intialisation\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# reference lines\n",
    "ax.plot([0, 1], ls = \"--\")  # blue diagonal\n",
    "ax.plot([0, 0], [1, 0], c=\".7\", ls='--')  # grey vertical\n",
    "ax.plot([1, 1], c=\".7\", ls='--')  # grey horizontal\n",
    "\n",
    "# roc curve\n",
    "ax.plot(false_positive_rate, recall)\n",
    "\n",
    "# labels\n",
    "ax.set_title(\"Receiver Operating Characteristic\")\n",
    "ax.set_xlabel(\"False Positive Rate\")\n",
    "ax.set_ylabel(\"Recall\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "# set-up for validation curve: which max_depth-settings to try\n",
    "search_space = range(2, 40,4)\n",
    "\n",
    "# initialize figures with two axes\n",
    "fig, ax = plt.subplots(ncols=3, figsize=[16, 4])\n",
    "fig.suptitle('Validation curves of RandomForestClassifier')\n",
    "\n",
    "# precision\n",
    "\n",
    "# calculate precision values of different hyperparameter settings and cross validation folds\n",
    "precision_train, precision_val = validation_curve(estimator=baseline_model.named_steps['model'], \n",
    "                                                  X=baseline_model.named_steps['preprocessing'].fit_transform(features_train, target_train), \n",
    "                                                  y=target_train, \n",
    "                                                  param_name='max_depth',\n",
    "                                                  param_range=search_space,\n",
    "                                                  cv=5,\n",
    "                                                  scoring='precision')\n",
    "\n",
    "# calculate average precision values for each hyperparameter setting\n",
    "precision_train_mean = np.mean(precision_train, axis=1)\n",
    "precision_val_mean = np.mean(precision_val, axis=1)\n",
    "\n",
    "# plot validation curve\n",
    "ax[0].plot(search_space,\n",
    "           precision_train_mean, label='precision train')\n",
    "ax[0].plot(search_space,\n",
    "           precision_val_mean, label='precision validation')\n",
    "ax[0].set(ylim=[0, 1.05],\n",
    "          xlabel='Decision levels (max_depth)',\n",
    "          ylabel='Precision score',\n",
    "          title='Precision score and Decision levels')\n",
    "ax[0].legend()\n",
    "\n",
    "# recall\n",
    "\n",
    "# calculate recall values of different hyperparameter settings and cross validation folds\n",
    "recall_train, recall_val = validation_curve(estimator=baseline_model.named_steps['model'], \n",
    "                                            X=baseline_model.named_steps['preprocessing'].fit_transform(features_train, target_train), \n",
    "                                            y=target_train, \n",
    "                                            param_name='max_depth',\n",
    "                                            param_range=search_space,\n",
    "                                            cv=5,\n",
    "                                            scoring='recall')\n",
    "\n",
    "# calculate average recall values for each hyperparameter setting\n",
    "recall_train_mean = np.mean(recall_train, axis=1)\n",
    "recall_val_mean = np.mean(recall_val, axis=1)\n",
    "\n",
    "# plot validation curve\n",
    "ax[1].plot(search_space,\n",
    "           recall_train_mean, label='recall train')\n",
    "ax[1].plot(search_space,\n",
    "           recall_val_mean, label='recall validation')\n",
    "ax[1].set(ylim=[0, 1.05],\n",
    "          xlabel='Decision levels (max_depth)',\n",
    "          ylabel='Recall score',\n",
    "          title='Recall score and Decision levels')\n",
    "ax[1].legend()\n",
    "\n",
    "# f1 score\n",
    "\n",
    "# calculate precision values of different hyperparameter settings and cross validation folds\n",
    "precision_train, precision_val = validation_curve(estimator=baseline_model.named_steps['model'], \n",
    "                                                  X=baseline_model.named_steps['preprocessing'].fit_transform(features_train, target_train), \n",
    "                                                  y=target_train, \n",
    "                                                  param_name='max_depth',\n",
    "                                                  param_range=search_space,\n",
    "                                                  cv=5,\n",
    "                                                  scoring='f1')\n",
    "\n",
    "# calculate average precision values for each hyperparameter setting\n",
    "precision_train_mean = np.mean(precision_train, axis=1)\n",
    "precision_val_mean = np.mean(precision_val, axis=1)\n",
    "\n",
    "# plot validation curve\n",
    "ax[2].plot(search_space,\n",
    "           precision_train_mean, label='f1 train')\n",
    "ax[2].plot(search_space,\n",
    "           precision_val_mean, label='f1 validation')\n",
    "ax[2].set(ylim=[0, 1.05],\n",
    "          xlabel='Decision levels (max_depth)',\n",
    "          ylabel='F1 score',\n",
    "          title='F1 score and Decision levels')\n",
    "ax[2].legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. RandomForestClassifier with only the 12 most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(grid):\n",
    "    \"\"\"Add new Features to Dataframe.\n",
    "    \n",
    "    Extract the 12 most important features of a given model.\n",
    "       \n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe\n",
    "    \n",
    "    Returns:\n",
    "        (list) : list of column names\n",
    "    \"\"\" \n",
    "    feature_importances = pd.DataFrame(grid.estimator.named_steps['classifier'].feature_importances_, index=grid.estimator.named_steps['preprocessing'].get_feature_names_out())\n",
    "    feature_importances = feature_importances.sort_values(by=0, ascending=True)\n",
    "\n",
    "    return feature_importances.tail(12).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save feature_selection as pickle\n",
    "pickle.dump(feature_selection, open('feature_selection.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load feature_selection\n",
    "file_name = 'feature_selection.p'\n",
    "#with (open(file_name, \"rb\")) as f:\n",
    "feature_selection = pickle.load(open(file_name, 'rb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folgende Code-Zeile löschen wir evntuell noch, da es noch nicht funktioniert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestClassification with feature selection\n",
    "# don't work right now\n",
    "\n",
    "# grid_log.estimator.steps[1][1].feature_importances_\n",
    "# grid_rf.__dict__\n",
    "# grid_log.estimator.steps[2][1]\n",
    "# grid_log.estimator.__dict__\n",
    "# grid_log.__dict__\n",
    "# grid_rf.estimator.named_steps['classifier'].feature_importances_\n",
    "\n",
    "most_important_features = feature_selection(grid_rf)\n",
    "display(most_important_features)\n",
    "\n",
    "# pipe with feature selection\n",
    "pipe_rf = Pipeline([('preprocessing', ColumnTransformer(transformers=[\n",
    "                         ('encoder', OneHotEncoder(handle_unknown='ignore'), cat_cols),\n",
    "                         ('ord_transformer', OrdinalEncoder(), ord_cols),\n",
    "  \t\t\t                  ('keep_cols', 'passthrough', most_important_features)\n",
    "                      ], remainder='drop')),\n",
    "                      ('classifier', grid_rf.estimator.named_steps['classifier'])])\n",
    "\n",
    "# Train the RandomForestClassifier\n",
    "pipe_rf.fit(features_train, target_train)\n",
    "\n",
    "# Print the training score of the best model\n",
    "print(\"best score\", pipe_rf.best_score_)\n",
    "\n",
    "# Print the model parameters of the best model\n",
    "print(\"best model parameter\", pipe_rf.best_params_)\n",
    "\n",
    "pipe_rf.fit(features_train, target_train)\n",
    "\n",
    "#predict\n",
    "target_test_pred_rf_grid_sel = grid_rf.predict(features_test)\n",
    "\n",
    "#save\n",
    "scores = {'name': \"RandomForest optimized with feature selection\",\n",
    "          'accuracy': accuracy_score(target_test, target_test_pred_rf_grid_sel) * 100,\n",
    "          'precision': precision_score(target_test, target_test_pred_rf_grid_sel) * 100,\n",
    "          'recall': recall_score(target_test, target_test_pred_rf_grid_sel) * 100,\n",
    "          'f1': f1_score(target_test, target_test_pred_rf_grid_sel) * 100,\n",
    "        }\n",
    "model_results.append(scores)\n",
    "    \n",
    "#show results\n",
    "pd.DataFrame(model_results).T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. RandomForest with polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestClassifier with PolynomialFeatures\n",
    "# running time: 25m 26.6s\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "#initate PolynomialFeatures\n",
    "poly_transformer = PolynomialFeatures(degree=2,           \n",
    "                                      interaction_only=False, # Controls whether self interactons are included \n",
    "                                      include_bias=False)    # Controls whether the 1 is also icluded as a feature\n",
    "\n",
    "#create Pipeline\n",
    "pipeline_rf_poly = Pipeline([('preprocessing', ColumnTransformer(transformers=[\n",
    "                    ('encoder', OneHotEncoder(handle_unknown='ignore'), cat_cols),\n",
    "                     ('ord_transformer', OrdinalEncoder(), ord_cols)\n",
    "                    ], remainder='passthrough')),\n",
    "                    ('scaler', StandardScaler()),\n",
    "                    (\"poly\", poly_transformer),\n",
    "                    ('classifier', RandomForestClassifier(class_weight=\"balanced\", random_state=42))])\n",
    "\n",
    "# Create the parameter grid\n",
    "grid_search_rf_poly = [{'classifier__max_depth':range(2, 40,4),#[10,11,12,13,14,15, 20],       \n",
    "                  'classifier__max_features':[2, 3, 4, 5, 6, 8, 20,\"auto\"],\n",
    "                  'classifier__min_samples_split':[2, 3, 4],\n",
    "                  'classifier__min_samples_leaf':[2, 3, 4],\n",
    "                  'classifier__n_estimators': np.arange(10,150,20)\n",
    "                }]\n",
    "\n",
    "# Create an instance of GridSearch \n",
    "grid_rf_poly = GridSearchCV(estimator=pipeline_rf_poly,\n",
    "                    param_grid = grid_search_rf_poly,\n",
    "                    scoring='f1',\n",
    "                    cv=5,\n",
    "                    n_jobs=-1)\n",
    "\n",
    "# Train the RandomForestClassifier\n",
    "grid_rf_poly.fit(features_train, target_train)\n",
    "\n",
    "# Print the training score of the best model\n",
    "print(\"best score\")\n",
    "print(grid_rf_poly.best_score_)\n",
    "\n",
    "# Print the model parameters of the best model\n",
    "print(\"best model parameter\")\n",
    "print(grid_rf_poly.best_params_)\n",
    "\n",
    "#predict\n",
    "target_test_pred_rf_poly_grid = grid_rf_poly.best_estimator_.predict(features_test)\n",
    "\n",
    "#save\n",
    "scores = {'name': \"RandomForest with polynomial features\",\n",
    "          'accuracy': accuracy_score(target_test, target_test_pred_rf_poly_grid) * 100,\n",
    "          'precision': precision_score(target_test, target_test_pred_rf_poly_grid) * 100,\n",
    "          'recall': recall_score(target_test, target_test_pred_rf_poly_grid) * 100,\n",
    "          'f1': f1_score(target_test, target_test_pred_rf_poly_grid) * 100,\n",
    "        }\n",
    "model_results.append(scores)\n",
    "    \n",
    "#show results\n",
    "pd.DataFrame(model_results).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Alive', 'Dead']\n",
    "cm = confusion_matrix(target_test, target_test_pred_rf_poly_grid)\n",
    "plt.figure(figsize = (8,8))\n",
    "sns.heatmap(cm, annot = True, fmt='', xticklabels = labels, yticklabels = labels)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report\n",
    "report = classification_report(target_test, target_test_pred_rf_poly_grid)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print roc-curve\n",
    "\n",
    "# create DataFrame with one column named prediction\n",
    "df_pred_test = pd.DataFrame(target_test_pred_rf_poly_grid, columns=['prediction'])\n",
    "\n",
    "# predict probabilities and add them as new column\n",
    "df_pred_test.loc[:, 'probability'] = grid_rf_poly.best_estimator_.predict_proba(features_test)[:, 1]  \n",
    "\n",
    "# calculate roc-curve\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "false_positive_rate, recall, threshold = roc_curve(target_test, df_pred_test.loc[:, 'probability']) \n",
    "\n",
    "# plotting\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# figure and axes intialisation\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# reference lines\n",
    "ax.plot([0, 1], ls = \"--\")  # blue diagonal\n",
    "ax.plot([0, 0], [1, 0], c=\".7\", ls='--')  # grey vertical\n",
    "ax.plot([1, 1], c=\".7\", ls='--')  # grey horizontal\n",
    "\n",
    "# roc curve\n",
    "ax.plot(false_positive_rate, recall)\n",
    "\n",
    "# labels\n",
    "ax.set_title(\"Receiver Operating Characteristic\")\n",
    "ax.set_xlabel(\"False Positive Rate\")\n",
    "ax.set_ylabel(\"Recall\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save grid_rf_poly as pickle\n",
    "\n",
    "pickle.dump(grid_rf_poly, open('grid_rf_poly.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load grid_rf_poly\n",
    "file_name = 'grid_rf_poly.p'\n",
    "grid_rf_poly = pickle.load(open(file_name, 'rb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score\n",
      "0.8698415346121768\n",
      "best model parameter\n",
      "{'classifier__C': 0.0017575106248547913, 'classifier__penalty': 'l1'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>LogisticRegression_GridSearch</td>\n",
       "      <td>LogisticRegression_GridSearch_recall</td>\n",
       "      <td>LogisticRegression_GridSearch_RobustScaler</td>\n",
       "      <td>LogisticRegression_GridSearch</td>\n",
       "      <td>LogisticRegression_GridSearch_recall</td>\n",
       "      <td>LogisticRegression_GridSearch</td>\n",
       "      <td>LogisticRegression_GridSearch</td>\n",
       "      <td>LogisticRegression_GridSearch</td>\n",
       "      <td>LogisticRegression_GridSearch</td>\n",
       "      <td>LogisticRegression_GridSearch</td>\n",
       "      <td>LogisticRegression_GridSearch_recall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>82.133995</td>\n",
       "      <td>82.133995</td>\n",
       "      <td>82.382134</td>\n",
       "      <td>82.133995</td>\n",
       "      <td>82.133995</td>\n",
       "      <td>82.382134</td>\n",
       "      <td>82.382134</td>\n",
       "      <td>65.260546</td>\n",
       "      <td>65.260546</td>\n",
       "      <td>82.382134</td>\n",
       "      <td>65.260546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>49.107143</td>\n",
       "      <td>49.107143</td>\n",
       "      <td>49.54955</td>\n",
       "      <td>49.107143</td>\n",
       "      <td>49.107143</td>\n",
       "      <td>49.54955</td>\n",
       "      <td>49.54955</td>\n",
       "      <td>32.5</td>\n",
       "      <td>32.5</td>\n",
       "      <td>49.54955</td>\n",
       "      <td>32.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>78.571429</td>\n",
       "      <td>78.571429</td>\n",
       "      <td>78.571429</td>\n",
       "      <td>78.571429</td>\n",
       "      <td>78.571429</td>\n",
       "      <td>78.571429</td>\n",
       "      <td>78.571429</td>\n",
       "      <td>92.857143</td>\n",
       "      <td>92.857143</td>\n",
       "      <td>78.571429</td>\n",
       "      <td>92.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>60.43956</td>\n",
       "      <td>60.43956</td>\n",
       "      <td>60.773481</td>\n",
       "      <td>60.43956</td>\n",
       "      <td>60.43956</td>\n",
       "      <td>60.773481</td>\n",
       "      <td>60.773481</td>\n",
       "      <td>48.148148</td>\n",
       "      <td>48.148148</td>\n",
       "      <td>60.773481</td>\n",
       "      <td>48.148148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      0   \\\n",
       "name       LogisticRegression_GridSearch   \n",
       "accuracy                       82.133995   \n",
       "precision                      49.107143   \n",
       "recall                         78.571429   \n",
       "f1                              60.43956   \n",
       "\n",
       "                                             1   \\\n",
       "name       LogisticRegression_GridSearch_recall   \n",
       "accuracy                              82.133995   \n",
       "precision                             49.107143   \n",
       "recall                                78.571429   \n",
       "f1                                     60.43956   \n",
       "\n",
       "                                                   2   \\\n",
       "name       LogisticRegression_GridSearch_RobustScaler   \n",
       "accuracy                                    82.382134   \n",
       "precision                                    49.54955   \n",
       "recall                                      78.571429   \n",
       "f1                                          60.773481   \n",
       "\n",
       "                                      3   \\\n",
       "name       LogisticRegression_GridSearch   \n",
       "accuracy                       82.133995   \n",
       "precision                      49.107143   \n",
       "recall                         78.571429   \n",
       "f1                              60.43956   \n",
       "\n",
       "                                             4   \\\n",
       "name       LogisticRegression_GridSearch_recall   \n",
       "accuracy                              82.133995   \n",
       "precision                             49.107143   \n",
       "recall                                78.571429   \n",
       "f1                                     60.43956   \n",
       "\n",
       "                                      5                              6   \\\n",
       "name       LogisticRegression_GridSearch  LogisticRegression_GridSearch   \n",
       "accuracy                       82.382134                      82.382134   \n",
       "precision                       49.54955                       49.54955   \n",
       "recall                         78.571429                      78.571429   \n",
       "f1                             60.773481                      60.773481   \n",
       "\n",
       "                                      7                              8   \\\n",
       "name       LogisticRegression_GridSearch  LogisticRegression_GridSearch   \n",
       "accuracy                       65.260546                      65.260546   \n",
       "precision                           32.5                           32.5   \n",
       "recall                         92.857143                      92.857143   \n",
       "f1                             48.148148                      48.148148   \n",
       "\n",
       "                                      9                                     10  \n",
       "name       LogisticRegression_GridSearch  LogisticRegression_GridSearch_recall  \n",
       "accuracy                       82.382134                             65.260546  \n",
       "precision                       49.54955                                  32.5  \n",
       "recall                         78.571429                             92.857143  \n",
       "f1                             60.773481                             48.148148  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "# scoring \"recall\": accuracy: 65.2, precision: 32, recall: 92.8, F1: 48.1\n",
    "# using RobustScaler yields minimal improvement\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# create Pipeline\n",
    "pipeline_log = Pipeline([('preprocessing', ColumnTransformer(transformers=[\n",
    "                    ('encoder', OneHotEncoder(handle_unknown='ignore'), cat_cols),\n",
    "                     ('ord_transformer', OrdinalEncoder(), ord_cols),\n",
    "                     #('poly', PolynomialFeatures(degree=2, include_bias=False), num_cols),\n",
    "                     ], remainder='passthrough')),\n",
    "                    ('scaler', RobustScaler()),\n",
    "                    ('classifier', LogisticRegression(solver=\"liblinear\", class_weight='balanced', max_iter=1000, random_state=42))])\n",
    "\n",
    "# create C_values\n",
    "C_values = np.geomspace(0.001,1000,50) #[0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "# creat parameter Grid\n",
    "grid_search_log = [{'classifier__penalty':[\"l2\",\"l1\"],\n",
    "                    'classifier__C': C_values\n",
    "                }]\n",
    "\n",
    "# Create an instance of GridSearch Cross-validation estimator\n",
    "grid_log = GridSearchCV(estimator=pipeline_log,\n",
    "                     param_grid = grid_search_log,\n",
    "                     scoring='f1',\n",
    "                     cv=5,   \n",
    "                     n_jobs=-1)\n",
    "\n",
    "# Train the RandomForestClassifier\n",
    "grid_log.fit(features_train, target_train)\n",
    "\n",
    "# Print the training score of the best model\n",
    "print(\"best score\")\n",
    "print(grid_log.best_score_)\n",
    "\n",
    "# Print the model parameters of the best model\n",
    "print(\"best model parameter\")\n",
    "print(grid_log.best_params_)\n",
    "\n",
    "# Print the test score of the best model\n",
    "#predict\n",
    "target_test_pred_log_grid = grid_log.best_estimator_.predict(features_test)\n",
    "\n",
    "#save\n",
    "scores = {'name': \"LogisticRegression_GridSearch\",\n",
    "          'accuracy': accuracy_score(target_test, target_test_pred_log_grid) * 100,\n",
    "          'precision': precision_score(target_test, target_test_pred_log_grid) * 100,\n",
    "          'recall': recall_score(target_test, target_test_pred_log_grid) * 100,\n",
    "          'f1': f1_score(target_test, target_test_pred_log_grid) * 100,\n",
    "         }\n",
    "model_results.append(scores)\n",
    "    \n",
    "#show results\n",
    "pd.DataFrame(model_results).T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Alive', 'Dead']\n",
    "cm = confusion_matrix(target_test, target_test_pred_log_grid)\n",
    "plt.figure(figsize = (8,8))\n",
    "sns.heatmap(cm, annot = True, fmt='', xticklabels = labels, yticklabels = labels)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report\n",
    "report = classification_report(target_test, target_test_pred_log_grid)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print roc-curve\n",
    "\n",
    "# create DataFrame with one column named prediction\n",
    "df_pred_test = pd.DataFrame(target_test_pred_log_grid, columns=['prediction'])\n",
    "\n",
    "# predict probabilities and add them as new column\n",
    "df_pred_test.loc[:, 'probability'] = grid_log.best_estimator_.predict_proba(features_test)[:, 1]  \n",
    "\n",
    "# calculate roc-curve\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "false_positive_rate, recall, threshold = roc_curve(target_test, df_pred_test.loc[:, 'probability']) \n",
    "\n",
    "# plotting\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# figure and axes intialisation\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# reference lines\n",
    "ax.plot([0, 1], ls = \"--\")  # blue diagonal\n",
    "ax.plot([0, 0], [1, 0], c=\".7\", ls='--')  # grey vertical\n",
    "ax.plot([1, 1], c=\".7\", ls='--')  # grey horizontal\n",
    "\n",
    "# roc curve\n",
    "ax.plot(false_positive_rate, recall)\n",
    "\n",
    "# labels\n",
    "ax.set_title(\"Receiver Operating Characteristic\")\n",
    "ax.set_xlabel(\"False Positive Rate\")\n",
    "ax.set_ylabel(\"Recall\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save grid_log as pickle\n",
    "\n",
    "pickle.dump(grid_log, open('grid_log.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load grid_log\n",
    "file_name = 'grid_log.p'\n",
    "grid_log = pickle.load(open(file_name, 'rb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Support Vector Machine with Gaussian kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support Vector Machine with Gaussian kernel\n",
    "# running time: 12.9s\n",
    "\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "# create Pipeline\n",
    "pipeline_svc = Pipeline([('preprocessing', ColumnTransformer(transformers=[\n",
    "                    ('encoder', OneHotEncoder(handle_unknown='ignore'), cat_cols),\n",
    "                     ('ord_transformer', OrdinalEncoder(), ord_cols)\n",
    "                    ], remainder='passthrough')),\n",
    "                    ('scaler', StandardScaler()),\n",
    "                    ('classifier', SVC(C=1000, kernel=\"rbf\", gamma='scale', class_weight='balanced', random_state=42))])\n",
    "\n",
    "# create k values\n",
    "k = np.geomspace(1,1000,10, dtype=\"int\")\n",
    "k = np.unique(k)\n",
    "\n",
    "# Create the parameter grid\n",
    "grid_search_svc = [{'classifier__C':[0.1,1, 10, 100],\n",
    "                   'classifier__gamma':[0.001,0.01,0.1, 1, 10]\n",
    "                    }]\n",
    "\n",
    "# Create an instance of GridSearch Cross-validation estimator\n",
    "grid_svc = GridSearchCV(estimator=pipeline_svc,\n",
    "                     param_grid = grid_search_svc,\n",
    "                     scoring='f1',\n",
    "                     cv=3,\n",
    "                     verbose =1,\n",
    "                     n_jobs=-1)\n",
    "\n",
    "# fit the Model\n",
    "grid_svc.fit(features_train, target_train)\n",
    "\n",
    "# Print the training score of the best model\n",
    "print(\"best score\")\n",
    "print(grid_svc.best_score_)\n",
    "\n",
    "# Print the model parameters of the best model\n",
    "print(\"best model parameter\")\n",
    "print(grid_svc.best_params_)\n",
    "\n",
    "# Print the test score of the best model\n",
    "#predict\n",
    "target_test_pred_svc_grid = grid_svc.predict(features_test)\n",
    "\n",
    "#save\n",
    "scores = {'name': \"SVC with Gaussian kernel and GridSearch\",\n",
    "          'accuracy': accuracy_score(target_test, target_test_pred_svc_grid) * 100,\n",
    "          'precision': precision_score(target_test, target_test_pred_svc_grid) * 100,\n",
    "          'recall': recall_score(target_test, target_test_pred_svc_grid) * 100,\n",
    "          'f1': f1_score(target_test, target_test_pred_svc_grid) * 100,\n",
    "         }\n",
    "model_results.append(scores)\n",
    "    \n",
    "#show results\n",
    "pd.DataFrame(model_results).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# confusion matrix for predictions on test data\n",
    "plt.style.use('classic')\n",
    "test_pred = grid_svc.best_estimator_.predict(features_test)\n",
    "confusion_matrix(target_test, test_pred)\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(grid_svc, features_test, target_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report\n",
    "report = classification_report(target_test, target_test_pred_svc_grid)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save grid_log as pickle\n",
    "\n",
    "pickle.dump(grid_svc, open('grid_svc.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load grid_svc\n",
    "file_name = 'grid_svc.p'\n",
    "grid_svc = pickle.load(open(file_name, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print roc-curve\n",
    "\n",
    "# # create DataFrame with one column named prediction\n",
    "# df_pred_test = pd.DataFrame(target_test_pred_svc_grid, columns=['prediction'])\n",
    "\n",
    "# # predict probabilities and add them as new column\n",
    "# df_pred_test.loc[:, 'probability'] = grid_svc.best_estimator_.predict_proba(features_test)[:, 1]  \n",
    "\n",
    "# # calculate roc-curve\n",
    "# from sklearn.metrics import roc_curve\n",
    "\n",
    "# false_positive_rate, recall, threshold = roc_curve(target_test, df_pred_test.loc[:, 'probability']) \n",
    "\n",
    "# # plotting\n",
    "# plt.style.use('ggplot')\n",
    "\n",
    "# # figure and axes intialisation\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# # reference lines\n",
    "# ax.plot([0, 1], ls = \"--\")  # blue diagonal\n",
    "# ax.plot([0, 0], [1, 0], c=\".7\", ls='--')  # grey vertical\n",
    "# ax.plot([1, 1], c=\".7\", ls='--')  # grey horizontal\n",
    "\n",
    "# # roc curve\n",
    "# ax.plot(false_positive_rate, recall)\n",
    "\n",
    "# # labels\n",
    "# ax.set_title(\"Receiver Operating Characteristic\")\n",
    "# ax.set_xlabel(\"False Positive Rate\")\n",
    "# ax.set_ylabel(\"Recall\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portfolio_minimal_ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
