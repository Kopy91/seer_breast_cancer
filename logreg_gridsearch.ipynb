{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline modelfrom sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# select cat columns\n",
    "categorical_columns = features_train.select_dtypes(include=[\"category\"]).columns.tolist()\n",
    "\n",
    "# build pipeline with scaler, encoder, logreg\n",
    "pipeline = Pipeline([('preprocessor', ColumnTransformer([\n",
    "                    ('encoder', OneHotEncoder(), categorical_columns)], remainder='passthrough')),\n",
    "                    ('scaler', StandardScaler()),\n",
    "                    ('classifier', LogisticRegression(random_state=42, class_weight='balanced'))])\n",
    "# use label encoding\n",
    "\n",
    "\n",
    "pipeline.fit(features_train, target_train)\n",
    "\n",
    "# Predict on the testing data\n",
    "target_pred = pipeline.predict(features_test)\n",
    "\n",
    "# report\n",
    "report = classification_report(target_test, target_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importances\n",
    "\n",
    "feature_importances = pipeline.named_steps['classifier'].coef_[0]\n",
    "feature_names = pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False).head(10)\n",
    "\n",
    "print(\"\\nTop 10 Feature Importances:\\n\", importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'preprocessor__encoder__drop': [None, 'first'],\n",
    "    'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'classifier__penalty': ['l2'],\n",
    "    'classifier__solver': ['liblinear', 'lbfgs'],\n",
    "    'classifier__max_iter': [100, 200, 300]}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# Fit the grid search to find the best parameters\n",
    "grid_search.fit(features_train, target_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n",
    "\n",
    "# Predict on the testing data using the best estimator\n",
    "best_estimator = grid_search.best_estimator_\n",
    "target_pred = best_estimator.predict(features_test)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
